{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "import copy\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_concept_pairs(spark, phenotype_concepts_input, phenotype_concepts_out, save_pair_concepts=True, header=\"true\", delimiter=\"\\t\"):\n",
    "    #Load the data into the spark dataframe\n",
    "    phenotypeDF_1 = spark.read \\\n",
    "        .option(\"header\", header) \\\n",
    "        .option(\"delimiter\", delimiter) \\\n",
    "        .csv(phenotype_concepts_input)\n",
    "        #.withColumn(\"rank\", dense_rank().over(Window.partitionBy(\"phenotype_name\").orderBy(desc(\"source_concept_id\"))))\n",
    "    \n",
    "    #Load the data into the spark dataframe again for performing self join later \n",
    "    phenotypeDF_2 = phenotypeDF_1.rdd.toDF(phenotypeDF_1.schema)\n",
    "    \n",
    "    #Alias the columns for the pairwise concepts within the same phenotype definitions\n",
    "    columns = [phenotypeDF_1[\"phenotype_name\"],\n",
    "           phenotypeDF_1[\"source_concept_id\"].alias(\"source_concept_id_1\"),\n",
    "           phenotypeDF_1[\"standard_concept_id\"].alias(\"standard_concept_id_1\"),\n",
    "           phenotypeDF_1[\"source_name\"].alias(\"source_name_1\"),\n",
    "           phenotypeDF_1[\"source_vocabulary\"].alias(\"source_vocabulary_1\"),\n",
    "           phenotypeDF_1[\"source_domain\"].alias(\"source_domain_1\"),\n",
    "           phenotypeDF_1[\"standard_name\"].alias(\"standard_name_1\"),\n",
    "           phenotypeDF_1[\"standard_vocabulary\"].alias(\"standard_vocabulary_1\"),\n",
    "           phenotypeDF_1[\"standard_domain\"].alias(\"standard_domain_1\"),\n",
    "           phenotypeDF_2[\"source_concept_id\"].alias(\"source_concept_id_2\"),\n",
    "           phenotypeDF_2[\"standard_concept_id\"].alias(\"standard_concept_id_2\"),\n",
    "           phenotypeDF_2[\"source_name\"].alias(\"source_name_2\"),\n",
    "           phenotypeDF_2[\"source_vocabulary\"].alias(\"source_vocabulary_2\"),\n",
    "           phenotypeDF_2[\"source_domain\"].alias(\"source_domain_2\"),\n",
    "           phenotypeDF_2[\"standard_name\"].alias(\"standard_name_2\"),\n",
    "           phenotypeDF_2[\"standard_vocabulary\"].alias(\"standard_vocabulary_2\"),\n",
    "           phenotypeDF_2[\"standard_domain\"].alias(\"standard_domain_2\"),\n",
    "          ]\n",
    "    #Create all combinations of concept pairs within the same phenotype definitions. \n",
    "    #Self join the phenotype dataset where rows are NOT the same\n",
    "    pair_concepts = phenotypeDF_1.join(phenotypeDF_2, phenotypeDF_1[\"phenotype_name\"] == phenotypeDF_2[\"phenotype_name\"]) \\\n",
    "        .where((phenotypeDF_1[\"standard_concept_id\"] != phenotypeDF_2[\"standard_concept_id\"])\n",
    "           | (phenotypeDF_1[\"source_concept_id\"] != phenotypeDF_2[\"source_concept_id\"])) \\\n",
    "        .select(columns).orderBy(phenotypeDF_1[\"phenotype_name\"])\n",
    "    \n",
    "    #determine if we need to save the dataframe to the disk\n",
    "    if save_pair_concepts:\n",
    "        #Save the paired concepts to a file\n",
    "        pair_concepts.write \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .format(\"csv\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save(\"phenotype_paired_concepts\")\n",
    "    \n",
    "    #extract all phenotype related concepts\n",
    "    phenotype_concepts = phenotypeDF_1.select(col(\"standard_concept_id\").alias(\"concept_id\")) \\\n",
    "        .union(phenotypeDF_1.select(col(\"source_concept_id\").alias(\"concept_id\"))) \\\n",
    "        .distinct();\n",
    "    \n",
    "    return (pair_concepts, phenotype_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cdm_tables(spark, property_ini_file_path):\n",
    "    \n",
    "    #Parse the properties\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(property_ini_file_path)\n",
    "    properties = config.defaults()\n",
    "    base_url = properties[\"base_url\"]\n",
    "    \n",
    "    #Load visit_occurrence\n",
    "    visit_occurrence = spark.read \\\n",
    "        .jdbc(base_url, \"dbo.visit_occurrence\", properties=properties)\n",
    "\n",
    "    #Load condition_occurrence\n",
    "    condition_occurrence = spark.read \\\n",
    "        .jdbc(base_url, \"dbo.condition_occurrence\", properties=properties)\n",
    "\n",
    "    #Load drug_exposure\n",
    "    drug_exposure = spark.read \\\n",
    "        .jdbc(base_url, \"dbo.drug_exposure\", properties=properties)\n",
    "\n",
    "    #Load procedure_occurrence\n",
    "    procedure_occurrence = spark.read \\\n",
    "        .jdbc(base_url, \"dbo.procedure_occurrence\", properties=properties)\n",
    "\n",
    "    #Load measurement\n",
    "    measurement = spark.read \\\n",
    "        .jdbc(base_url, \"dbo.measurement\", properties=properties)\n",
    "\n",
    "    #Load observation\n",
    "    observation = spark.read \\\n",
    "        .jdbc(base_url, \"dbo.observation\", properties=properties)\n",
    "        \n",
    "    return (visit_occurrence, condition_occurrence, drug_exposure, procedure_occurrence, measurement, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_domain_to_visit(domain_tables, visit_occurrence):\n",
    "    \n",
    "    joined_domain_tables = []\n",
    "    \n",
    "    for domain_table in domain_tables:\n",
    "        #extract the domain concept_id from the table fields. E.g. condition_concept_id from condition_occurrence\n",
    "        concept_id_field = [f for f in domain_table.schema.fieldNames() if \"concept_id\" in f][0]\n",
    "        #extract the name of the table\n",
    "        table_domain_field = concept_id_field.replace(\"_concept_id\", \"\")\n",
    "        #limit the domain records to those which have a visit_occurrence_id\n",
    "        joined_domain_table = domain_table \\\n",
    "            .join(v, domain_table[\"visit_occurrence_id\"] == v[\"visit_occurrence_id\"])\n",
    "        #standardize the output columns\n",
    "        joined_domain_tables.append(\n",
    "            joined_domain_table \\\n",
    "                .select(domain_table[\"person_id\"], \n",
    "                    domain_table[\"visit_occurrence_id\"], \n",
    "                    domain_table[concept_id_field].alias(\"standard_concept_id\"), \n",
    "                    lit(table_domain_field).alias(\"domain\"))\n",
    "        )\n",
    "        \n",
    "    return joined_domain_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patient_visit_concept(condition, \n",
    "                               drug, \n",
    "                               procedure, \n",
    "                               measurement, \n",
    "                               observation, \n",
    "                               patient_visit_concept_output,\n",
    "                               concept_occurrence_output):\n",
    "    \n",
    "    #Union person_id, visit_occurrence_id, and concept_id from all domains\n",
    "    patient_visit_concept = condition \\\n",
    "        .union(drug) \\\n",
    "        .union(procedure) \\\n",
    "        .union(measurement) \\\n",
    "        .union(observation) \\\n",
    "        .distinct() \\\n",
    "        .orderBy(\"person_id\", \"visit_occurrence_id\") \\\n",
    "        .where(col(\"standard_concept_id\") != 0)\n",
    "    \n",
    "    #Save the patient visit concept data \n",
    "    patient_visit_concept.write.option(\"header\", \"true\") \\\n",
    "        .format(\"csv\").mode(\"overwrite\") \\\n",
    "        .save(patient_visit_concept_output)\n",
    "    \n",
    "    #Create the concept occurrence matrix\n",
    "    concept_occurrence_matrix = patient_visit_concept \\\n",
    "        .groupBy(\"standard_concept_id\").count()\n",
    "        \n",
    "    #Save the patient visit concept data \n",
    "    concept_occurrence_matrix.write.option(\"header\", \"true\") \\\n",
    "        .format(\"csv\").mode(\"overwrite\") \\\n",
    "        .save(concept_occurrence_output)\n",
    "    \n",
    "    return (patient_visit_concept, concept_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cooccurrence_matrix(patient_visit_concept, concept_occurrence_matrix, cooccurrence_matrix_output, phenotype_concepts=None):\n",
    "     \n",
    "    #If phenotype_concepts is specified, the records that contain phenotype concepts are kept\n",
    "    if phenotype_concepts != None:\n",
    "        patient_visit_concept = patient_visit_concept \\\n",
    "        .join(phenotype_concepts, patient_visit_concept[\"standard_concept_id\"] == phenotype_concepts[\"concept_id\"]) \\\n",
    "        .select(patient_visit_concept[\"person_id\"], \n",
    "                patient_visit_concept[\"visit_occurrence_id\"], \n",
    "                patient_visit_concept[\"standard_concept_id\"], \n",
    "                patient_visit_concept[\"domain\"])\n",
    "    \n",
    "    #Add ranks to dataframe to avoid the symetric pairs generated by the self-join operation\n",
    "    patient_visit_concept = patient_visit_concept.withColumn(\"rank\", \n",
    "            dense_rank().over(Window.partitionBy(\"person_id\", \"visit_occurrence_id\").orderBy(desc(\"standard_concept_id\"))))\n",
    "    \n",
    "    #Make two copies of the patient_visit_concept dataframe for self-join\n",
    "    pvc_1 = patient_visit_concept.rdd.toDF(patient_visit_concept.schema)\n",
    "    pvc_2 = patient_visit_concept.rdd.toDF(patient_visit_concept.schema)\n",
    "    \n",
    "    #Create the cooccurrence matrix via a self-join where the concept_ids are NOT the same\n",
    "    cooccurrence_matrix = pvc_1 \\\n",
    "        .join(pvc_2, (pvc_1[\"person_id\"] == pvc_2[\"person_id\"])\n",
    "              & (pvc_1[\"visit_occurrence_id\"] == pvc_2[\"visit_occurrence_id\"])) \\\n",
    "        .where(pvc_1[\"standard_concept_id\"] != pvc_2[\"standard_concept_id\"]) \\\n",
    "        .select(pvc_1[\"person_id\"].alias(\"person_id\"),\n",
    "                pvc_1[\"standard_concept_id\"].alias(\"standard_concept_id_1\"), \n",
    "                pvc_2[\"standard_concept_id\"].alias(\"standard_concept_id_2\")) \\\n",
    "        .groupBy(\"standard_concept_id_1\", \"standard_concept_id_2\").count()\n",
    "    \n",
    "    cooccurrence_matrix = cooccurrence_matrix \\\n",
    "        .join(concept_occurrence_matrix, \n",
    "                        cooccurrence_matrix[\"standard_concept_id_1\"] == concept_occurrence_matrix[\"standard_concept_id\"]) \\\n",
    "        .select(cooccurrence_matrix[\"standard_concept_id_1\"],\n",
    "                cooccurrence_matrix[\"standard_concept_id_2\"],\n",
    "                cooccurrence_matrix[\"count\"],\n",
    "                concept_occurrence_matrix[\"count\"].alias(\"standard_concept_id_1_count\")\n",
    "               ) \\\n",
    "        .join(concept_occurrence_matrix, \n",
    "                        cooccurrence_matrix[\"standard_concept_id_2\"] == concept_occurrence_matrix[\"standard_concept_id\"]) \\\n",
    "        .select(cooccurrence_matrix[\"standard_concept_id_1\"],\n",
    "                cooccurrence_matrix[\"standard_concept_id_2\"],\n",
    "                cooccurrence_matrix[\"count\"],\n",
    "                col(\"standard_concept_id_1_count\"),\n",
    "                concept_occurrence_matrix[\"count\"].alias(\"standard_concept_id_2_count\")\n",
    "               ) \\\n",
    "        .withColumn(\"normalized_count\", col(\"count\") / (col(\"standard_concept_id_1_count\") + col(\"standard_concept_id_2_count\")))\n",
    "    \n",
    "    #Save the cooccurrence matrix\n",
    "    cooccurrence_matrix.write.option(\"header\", \"true\") \\\n",
    "        .format(\"csv\").mode(\"overwrite\").save(cooccurrence_matrix_output)\n",
    "    \n",
    "    return cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"Phenotype Cooccurrence\").getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "\n",
    "    pair_concepts, phenotype_concepts = \\\n",
    "        collect_concept_pairs(spark, \"phenotype_WG_concept_ids_from_eMERGE.tsv\", \"phenotype_paired_concepts\")\n",
    "\n",
    "    v, c, d, p, m, o = load_cdm_tables(spark, \"omop_database_properties.ini\")\n",
    "\n",
    "    c_filtered, d_filtered, p_filtered, m_filtered, o_filtered \\\n",
    "        = join_domain_to_visit([c, d, p, m, o], v)\n",
    "        \n",
    "    patient_visit_concept, concept_occurrence = create_patient_visit_concept(c_filtered, \n",
    "                                                                              d_filtered, \n",
    "                                                                              p_filtered, \n",
    "                                                                              m_filtered, \n",
    "                                                                              o_filtered, \n",
    "                                                                              \"patient_visit_concept\", \n",
    "                                                                              \"concept_occurrence\")\n",
    "        \n",
    "    #cooccurrence_matrix = create_cooccurrence_matrix(patient_visit_concept, \n",
    "    #                                                 concept_occurrence,\n",
    "    #                                                 \"cooccurrence_matrix\", \n",
    "    #                                                 phenotype_concepts)\n",
    "\n",
    "    cooccurrence_matrix_full = create_cooccurrence_matrix(patient_visit_concept, \n",
    "                                                     concept_occurrence,\n",
    "                                                     \"cooccurrence_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, c, d, p, m, o = load_cdm_tables(spark, \"omop_database_properties.ini.bak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
